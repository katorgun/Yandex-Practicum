{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Андрей! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.9/site-packages (1.9.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.9/site-packages (from wordcloud) (1.21.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot_metric in /opt/conda/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (1.21.1)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (0.11.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (0.24.1)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (0.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (1.9.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from plot_metric) (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot_metric) (8.4.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.23.4->plot_metric) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->plot_metric) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot_metric) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot_metric) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "import string\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from plot_metric.functions import BinaryClassification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')  # Download the POS tagger\n",
    "nltk.download('wordnet')  # Download WordNet words and synonyms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет:\n",
    "\n",
    "    \n",
    "    \n",
    "- у тебя тут есть лишние импорты, то что ты не использовано или использовано не верно - стоит убрать, чтобы поберечь ресурсы      \n",
    "\n",
    "    \n",
    "- есть рекомендации PEP-8 при написании кода, в том числе и для импортов. Если интересно можешь почитать [тут](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html). Есть что поправить \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in data = 159292\n",
      "Number of columns in data = 3\n",
      "Number of duplicates: 0\n",
      "Number of NA values: Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "**Sample data:**\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They wer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, Januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They wer...   \n",
       "1  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, Januar...   \n",
       "2  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relev...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics...   \n",
       "4                                  You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/datasets/toxic_comments.csv\"\n",
    "data_raw = pd.read_csv(data_path)\n",
    "print(\"Number of rows in data =\",data_raw.shape[0])\n",
    "print(\"Number of columns in data =\",data_raw.shape[1])\n",
    "print('Number of duplicates:', data_raw.duplicated().sum())\n",
    "print('Number of NA values:', data_raw.isna().sum())\n",
    "print(\"\\n\")\n",
    "print(\"**Sample data:**\")\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Если не знаешь - чтобы не было столбца  `Unnamed: 0` при чтении файла можно так:\n",
    "\n",
    "\n",
    "    pd.read_csv(..., index_col=0)\n",
    "\n",
    "    \n",
    "(`Unnamed: 0` появляется при не совсем корректном сохранении файла)    \n",
    "\n",
    "\n",
    "Unnamed: 0 это \"след\" старых индексов. Если ты уберёшь первые 10 примеров и своего датасета, сохранишь его, а потом откроешь,  то появится столбец Unnamed: 0 начиная с цифры 9, и появится новый индексы начиная с нуля \n",
    "\n",
    "\n",
    "Но это мелочь,  даже не нужно ничего исправлять. Просто знай, чтобы увидев такое в чужом коде не удивляться что бы это могло означать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='toxic', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'toxic', data = data_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Данные изучены. Небольшой EDA не помешает, так как это аналитический проект. \n",
    "\n",
    "\n",
    "Плюс за\n",
    "\n",
    "    \n",
    "\n",
    "-  проверку на сбалансированность \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- .sample() вместо .head(), ведь если данные каким то образом упорядоченны, то шансы увидеть что то разнообразное через .sample чуть выше чем через .head (или .tail)     \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже работает на локальном компьютере, возвращая картинки с облаком слов в зависимости от класса твитов (токсичные или не токчичные или все)\n",
    "Тут же я получаю ошибку \"ValueError: Only supported for TrueType fonts\"\n",
    "\n",
    "Ошибка \"Only supported for TrueType fonts\" обычно возникает из-за проблем с настройками шрифтов в matplotlib или среде выполнения кода. Ваша ошибка может быть связана с matplotlib, который пытается использовать шрифт, который не поддерживается. Нужно как то правильно задать шрифты, загрузив их в правильное место\n",
    "пробовал загружать в локальные папку TrueType шрифт # font_path = os.path.abspath('./LiberationSans-Regular.ttf')\n",
    "Но все равно не помогает\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "    \n",
    "Если погуглить, то есть такие варианты решения    \n",
    " \n",
    "В тренажере облако импортируем так\n",
    "\n",
    "\n",
    "\n",
    "    !/opt/conda/bin/python -m pip install wordcloud==1.8.2.2  \n",
    "\n",
    "\n",
    "И возможно дополнительно надо будет сделать\n",
    "\n",
    "\n",
    "\n",
    "    !pip install --upgrade Pillow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Укажем шрифт, который поддерживается вашей средой выполнения кода\n",
    "# # Например, шрифт 'Liberation Sans' поддерживается по умолчанию в большинстве сред\n",
    "# font_path = os.path.abspath('./LiberationSans-Regular.ttf')\n",
    "\n",
    "# df_toxic = data_raw[data_raw['toxic']==1]\n",
    "# df_nottoxic = data_raw[data_raw['toxic']==0]\n",
    "\n",
    "# All = \" \".join(review for review in data_raw.text)\n",
    "# toxic = \" \".join(review for review in df_toxic.text)\n",
    "# nottoxic = \" \".join(review for review in df_nottoxic.text)\n",
    "\n",
    "# fig, ax = plt.subplots(3, 1, figsize  = (30,30))\n",
    "# wordcloud_all = WordCloud(font_path=font_path,max_font_size=50, max_words=100, background_color=\"black\").generate(All)\n",
    "# wordcloud_toxic = WordCloud(font_path=font_path,max_font_size=50, max_words=100, background_color=\"black\").generate(toxic)\n",
    "# wordcloud_nottoxic = WordCloud(font_path=font_path,max_font_size=50, max_words=100, background_color=\"black\").generate(nottoxic)\n",
    "\n",
    "\n",
    "# ax[0].imshow(wordcloud_all, interpolation='bilinear')\n",
    "# ax[0].set_title('All comments', fontsize=30)\n",
    "# ax[0].axis('off')\n",
    "# ax[1].imshow(wordcloud_toxic, interpolation='bilinear')\n",
    "# ax[1].set_title('Toxic comments',fontsize=30)\n",
    "# ax[1].axis('off')\n",
    "# ax[2].imshow(wordcloud_nottoxic, interpolation='bilinear')\n",
    "# ax[2].set_title('NonToxic Comments',fontsize=30)\n",
    "# ax[2].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Optional Text](./download.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe345aefca0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOXIC_1 = data_raw[data_raw['toxic'] == 1]['text'].apply(lambda x: len(x) - len(' '))\n",
    "TOXIC_0 = data_raw[data_raw['toxic'] == 0]['text'].apply(lambda x: len(x) - len(' '))\n",
    "bins_ = np.linspace(0, 450, 70)\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.hist(TOXIC_1, bins= bins_, alpha = 0.5, label = 'Toxic comments')\n",
    "plt.hist(TOXIC_0, bins= bins_, alpha = 0.1, label = 'Non-toxic comments')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не токсичные комменты намного длиннее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы очистить текстовые данные, мы собираемся выполнить следующие шаги:\n",
    "\n",
    "1. Лемматизация мы превращаем любую форму слова в его корневое слово с библиотекой SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 37s, sys: 2.97 s, total: 35min 40s\n",
      "Wall time: 35min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Функция для лемматизации текста\n",
    "def clear_text(text):\n",
    "    return \" \".join(re.sub(r'[^a-zA-Z]', ' ', text.lower()).split())\n",
    "\n",
    "def lemmatize(text):\n",
    "    global nlp\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "# Применим функцию к столбцу 'text' в нашем dataframe\n",
    "data['clear_text'] = data['text'].apply(clear_text)\n",
    "\n",
    "data['lemmatized_text'] = data['clear_text'].apply(lemmatize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "spacy отлично подходит\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# # Function to convert nltk POS tags to wordnet tags\n",
    "# def nltk_to_wordnet_pos(nltk_pos):\n",
    "#     if nltk_pos.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif nltk_pos.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif nltk_pos.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif nltk_pos.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return wordnet.NOUN\n",
    "\n",
    "# def lemmatize_text(text):\n",
    "#     # Tokenize the text\n",
    "#     words = word_tokenize(text)\n",
    "    \n",
    "#     # POS tagging\n",
    "#     pos_tags = pos_tag(words)\n",
    "    \n",
    "#     # Lemmatize with POS tag\n",
    "#     lemmatized_words = [lemmatizer.lemmatize(word, nltk_to_wordnet_pos(pos)) for word, pos in pos_tags]\n",
    "    \n",
    "#     # Join the words back into a string\n",
    "#     lemmatized_text = ' '.join(lemmatized_words)\n",
    "    \n",
    "#     return lemmatized_text\n",
    "\n",
    "\n",
    "# # # Apply the function to the 'text' column of your dataframe\n",
    "# # data['lemmatized'] = data['text'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_lemmatized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lemmatized =  pd.read_csv(\"./data_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They wer...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my username hardcore metallica fan were reverted they weren...</td>\n",
       "      <td>explanation why the edit make under my username hardcore metallica fan be revert they weren t va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, Januar...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m seemingly stuck with thanks talk january utc</td>\n",
       "      <td>d aww he match this background colour I m seemingly stuck with thank talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relev...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s just that this guy is constantly removing relevan...</td>\n",
       "      <td>hey man I m really not try to edit war it s just that this guy be constantly remove relevant inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on improvement i wondered if the section statistics shoul...</td>\n",
       "      <td>more I can t make any real suggestion on improvement I wonder if the section statistic should be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember what page that s on</td>\n",
       "      <td>you sir be my hero any chance you remember what page that s on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They wer...   \n",
       "1  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, Januar...   \n",
       "2  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relev...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics...   \n",
       "4                                  You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      0   \n",
       "\n",
       "                                                                                            clear_text  \\\n",
       "0  explanation why the edits made under my username hardcore metallica fan were reverted they weren...   \n",
       "1             d aww he matches this background colour i m seemingly stuck with thanks talk january utc   \n",
       "2  hey man i m really not trying to edit war it s just that this guy is constantly removing relevan...   \n",
       "3  more i can t make any real suggestions on improvement i wondered if the section statistics shoul...   \n",
       "4                                      you sir are my hero any chance you remember what page that s on   \n",
       "\n",
       "                                                                                       lemmatized_text  \n",
       "0  explanation why the edit make under my username hardcore metallica fan be revert they weren t va...  \n",
       "1                d aww he match this background colour I m seemingly stuck with thank talk january utc  \n",
       "2  hey man I m really not try to edit war it s just that this guy be constantly remove relevant inf...  \n",
       "3  more I can t make any real suggestion on improvement I wonder if the section statistic should be...  \n",
       "4                                       you sir be my hero any chance you remember what page that s on  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "при помощи spacy лемматизировал текст и сохранил в локальный файл data.to_csv(\"data_lemmatized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer  рабочий вариант, но у него есть особенности, для корректной работы ему нужно передавать не просто слово, но и POS-тег (Part of Speech, части речи). Набираемся ума-разума [тут](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/) )  Обрати внимание на функцию `get_wordnet_pos`. Сразу хочу предупредить, что если делать Лемматизацию правильно, сучетом постегов, то время может занять полчаса-час. Так что не удивляйся (вообще советую сохранить результаты Лематизации в каком-то файлике, чтобы каждый раз не тратить на это много времени)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- лемматизацию можно было сделать с помощью SpaCy лемматизатором и прямо скажем как инструмент он более удобен и универсален, не нужно заморачиваться с токенизацией и учётом пос тегов\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Чтобы сэкономить время, и убедиться что всё отработало нормально, берёшь парочку предложений, создаёшь dataframe\n",
    "    \n",
    "    \n",
    "    sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "    sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "    df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "    print(df_my)\n",
    "\n",
    "\n",
    "    print(df_my['text'].apply(func))\n",
    "    \n",
    "    \n",
    "    \n",
    "И тестируешь не нем, должно получиться \n",
    "    \n",
    "    \n",
    "    \n",
    "    striped  ------> strip, went -------> go  \n",
    "\n",
    "\n",
    "\n",
    "Если всё получилось, то можно использовать на всём датасете"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Плюс за использование apply, неэффективные циклы нам ни к чему.\n",
    "\n",
    "\n",
    "- Да, всегда лучше проверить что получилось  в итоге, так всегда будет возможность поправить ошибку\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "    \n",
    "- попробуй .progress_apply, делает что .apply, но еще и показывает на какой итерации находится процесс.  \n",
    "\n",
    "Для некоторых версий, чтобы заработал .progress_apply предварительно нужно сделать:\n",
    "    \n",
    "    \n",
    "    from tqdm.notebook import tqdm\n",
    "    tqdm.pandas()\n",
    "    \n",
    "\n",
    "И cудя по всему импорты нужно засунуть внутрь функции\n",
    "\n",
    "То же самое делает .swifter.apply  Предварительно\n",
    "\n",
    "\n",
    "    !pip install swifter\n",
    "    import swifter\n",
    "\n",
    "\n",
    "Если  процесс лемматизации затягивается, можно попробовать [.parallel_apply](https://pypi.org/project/pandarallel/),  кому-то это помогает уменьшить время прогона кода раз в 5-7. А у большинства он вообще не запускается ) Предварительно: \n",
    "\n",
    "\n",
    "    \n",
    "    from pandarallel import pandarallel   \n",
    "    tqdm.pandas(desc=\"progress\")\n",
    "    pandarallel.initialize(progress_bar = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "- когда что то долго крутиться, можно использовать  %%time - ставишь на самый вверх ячейки с кодом, время выполнения которого хочешь замерить, может не знаешь.  Быстрее не станет, но все будут видеть стоит ли ждать не отходя от ПК или можно сходить чаек поставить ))  \n",
    "\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим набор данных на признаки и цели \n",
    "X = data['lemmatized_text']\n",
    "y = data['toxic']\n",
    "\n",
    "#Делим на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "- random_state на месте\n",
    "\n",
    "\n",
    "- правильно разбито на 2 выборки (иногда студенты использующие GS разбивают на 3 датасета)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- ' '.join можно было сразу добавить функцию lemmatizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- обрати внимание на аргумент stratify, он позволит сохранить изначальное распределение таргетов во всех новых датасетах.  Существующий дисбаланс никуда не денется, но в каждом датасете он будет одинаковым. [Почитать](https://pythonru.com/baza-znanij/sklearn-train-test-split) можно тут\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список моделей и параметров для поиска\n",
    "models_params = [\n",
    "    {\n",
    "        'classifier': [LogisticRegression(random_state=42)],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__C': np.logspace(-4, 4, 20),\n",
    "        'classifier__solver': ['liblinear']\n",
    "    },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [10, 50, 100, 200],\n",
    "        'classifier__max_features': [1, 'auto', None],\n",
    "        'classifier__max_depth' : [4, 5, 6, 7, 8]\n",
    "    }\n",
    "]\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "добавил random_state=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "Не забываем при инициализации модели о random_state, иначе после каждого запуска кода у нас может быть разный результат\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры:\n",
      "{'classifier__solver': 'liblinear', 'classifier__penalty': 'l2', 'classifier__C': 29.763514416313132, 'classifier': LogisticRegression(C=29.763514416313132, random_state=42, solver='liblinear')}\n",
      "F1-оценка на тренировочных данных: 0.954\n",
      "F1-оценка на тестовых данных: 0.788\n",
      "\n",
      "\n",
      "Лучшие параметры:\n",
      "{'classifier__n_estimators': 100, 'classifier__max_features': None, 'classifier__max_depth': 8, 'classifier': RandomForestClassifier(max_depth=8, max_features=None, random_state=42)}\n",
      "F1-оценка на тренировочных данных: 0.593\n",
      "F1-оценка на тестовых данных: 0.589\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# выполнить случайный поиск для каждой модели и набора параметров\n",
    "for params in models_params:\n",
    "    random_search = RandomizedSearchCV(pipe, param_distributions=params, cv=5, verbose=0, n_jobs=-1, scoring='f1')\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Лучшие параметры:\")\n",
    "    print(random_search.best_params_)\n",
    "\n",
    "    print(\"F1-оценка на тренировочных данных: {:.3f}\".format(f1_score(y_train, random_search.predict(X_train))))\n",
    "    print(\"F1-оценка на тестовых данных: {:.3f}\".format(f1_score(y_test, random_search.predict(X_test))))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "GridSearch (RandomizedSearchCV) + pipeline это уже другой уровень. Pipeline мало кто использует даже после совета, хотя он позволяет избежать утечки данных (особенно важно при использовании GridSearchCV/cross_val_score с предобработкой данных), и делает наш код лаконичней.\n",
    "\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:  \n",
    "\n",
    "\n",
    "\n",
    "На будущее    \n",
    "    \n",
    "    \n",
    "- Совет 1, развития темы использования pipeline\n",
    "    \n",
    "    \n",
    "Как создавать собственные функции в pipeline (мы пользовались стандартными из sklearn - Scaler, MinMax, или как в этом проекте TFIDF итп)    \n",
    "\n",
    "\n",
    "Можешь взять за основу [Ссылка 1](https://dzen.ru/media/id/5ee6f73b7cadb75a66e4c7e3/sozdanie-polzovatelskih-preobrazovatelei-dannyh-62b2a9a80e49941961ffc7a2),\n",
    "[Ссылка 2](https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "- Совет 2, как можно улучшить метрику использовав дополнительные признаки, опять же оформив это  в pipeline  \n",
    "    \n",
    "    \n",
    "\n",
    "Можешь попробовать  feature_engenering (Это когда мы создаём собственные признаки. Во многих случаях это более эффективный способ повысить нашу метрику,  чем долго обучать разные модели) c pipeline:   \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "1. Сгенерировать новые фичи, например например посчитать число слов в тексте, длину слов, число знаков препинания, число слов с заглавной итп итд. \n",
    "    \n",
    "   \n",
    "    \n",
    "2. Добавить к фичам от векторайзера\n",
    "    \n",
    "    \n",
    "Это можно было реализовать в последующей схеме через [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html):\n",
    "    \n",
    "    \n",
    "    new_features = ['lengh', 'number', ....]\n",
    "    # имена столбцов которых у нас записаны новые фичи (lengh - допустим длина слов твитах, number - количество слов в твите...). И пусть на эти признаки будем Scaler\n",
    "    \n",
    "    # lemmatized_text - столбец с текстом\n",
    "    \n",
    "    features = ColumnTransformer(\n",
    "                        [(\"text_preprocess\", TfidfVectorizer(stop_words=stopwords), \"lemmatized_text\"),\n",
    "                         (\"new_features_preprocess\", StandardScaler(), new_features)\n",
    "                        ])\n",
    "\n",
    "    \n",
    "    pipe = Pipeline([('features_all_prepross', features),\n",
    "                     ('model', LogisticRegression(random_state = 42))\n",
    "                    ])\n",
    "\n",
    "Какие именно признаки сгенерировать, это целое искусство. Студенты которые использовали библиотеку\n",
    "    \n",
    "    \n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer    \n",
    "\n",
    "смогли чуть поднять метрику )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузил данные\n",
    "2. Подготовил данные. Лематизация SpaCy, облако слов\n",
    "3. Обучил разные модели: При помощи pipe\n",
    "4. Сделал выводы:\n",
    "\n",
    "LogisticRegression удовлетворяет удовлетовряет условию для классификации твитов в f1_score 0.788"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "Общий вывод расписан и структурирован по логическим блокам проекта\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print('''учшие параметры:\n",
    "{'classifier__solver': 'liblinear', 'classifier__penalty': 'l2', 'classifier__C': 29.763514416313132, 'classifier': LogisticRegression(C=29.763514416313132, random_state=42, solver='liblinear')}\n",
    "F1-оценка на тренировочных данных: 0.954\n",
    "F1-оценка на тестовых данных: 0.788\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех: \n",
    "\n",
    "- Все верно, логика моделирования не нарушена, тут тестируем только лучшую модель отобранную на валидации, или парочку лучших, если на валидации результаты близки\n",
    "\n",
    "\n",
    "\n",
    "- Если студент получил на тесте f1 выше 0,75, это считается приемлемым результатом.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Что может помочь добиться лучшего результата (от простого)? \n",
    "\n",
    "\n",
    "- использовать stratify (возможно у тебя очень неудачный сплит, и распределение классов в новых выборках у тебя сильно отличается, хотя вероятность этого очень небольшая)\n",
    "    \n",
    "\n",
    "\n",
    "- можно поиграться [порогом](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/). Таким образом можно поднять метрику на процент - полтора\n",
    "   \n",
    "\n",
    "- учесть дисбаланс классов в таргете. (но не oversampling, это скользкая дорожка, через class_weight) Но порой это  приводит к ухудшению результата\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    " - полезно настраивать векторайзеры  (тут пригодится pipeline). Это конечно потребует вычислительных мощностей, ведь если даже использовать биграммы число признаков резко увеличится\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "- сгенерировать новые фичи, например  например посчитать число слов в тексте, длину слов итп итд. Или с помощью [тематического моделирования](https://pythobyte.com/python-for-nlp-topic-modeling-8fb3d689/) \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "- попробовать другие модели. проект своеобразный выбор между вычислительными ограничениями (много примеров, расчеты могут затянуться) и задачей получить хорошую метрику (как это и бывает на практике), поэтому советовать \"тяжелые\", но мощные модели, чтобы у тебя все окончательно не повисло не буду. Например использование случайного леса часто приводят к получению f1 = 0, потому что для этого датасета нужны деревья бОльше глубины, но это будет слишком долго считать.  И тут, градиентный бустинг, который используют деревья небольшой глубины, выигрывает, к тому же некоторые градиентные бустинги быстрые, это видно по их названию  (LightGBM).  \n",
    "\n",
    "\n",
    "\n",
    "- использование предбученной модели Берта, выбрав соответствующую модель и используя полученные эмбединги, даже на небольшом тренировочном датасете можно обучить модель, которая на test покажет хорошую метрику. В этом случаи можно сразу получить метрику > 0.95 (при правильно выбранной модели). Ниже подробнее\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "А ещё можешь посмотреть какие слова  является наиболее важным для классификации с точки зрения модели. Получаем список слов    \n",
    "    \n",
    "    \n",
    "    \n",
    "    .get_feature_names_out().tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "Получаем коэффициенты важности (для логистическая регрессии)    \n",
    "    \n",
    "    .coef_.tolist()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Альтернатива твоему подходу это использовать Берт.  В чём преимущество?!\n",
    "\n",
    "\n",
    "TF-IDF просто считает количество того или иного слова в предложении. Так он переводит текст, который непонятен компьютеру, в числа. Но можно ведь сделать посложнее, и в качестве слова взять вектор, причём так что вектор слово \"мужчина\" и вектор слова \"человек\" были близки - то есть тут уже учитывается внутренняя материя языка. Или например известный пример: создаем такие вектора слов, что если от вектора слова \"король\", отнять Вектор слова \"мужчина\" и добавить Вектор слова \"женщина\", то получится Вектор близкий к вектору слова \"Королева\".  Это можно получить с помощью Word2Vec. Но на самом деле эмбединги (вектора) слов от Берта и подобных ему моделей (Называются модели с Улицы Сезам) еще круче, потому что они ещё и учитывают контекст слова, то есть он работает с целым предложением, и теперь эмбединг одного и того же слова может отличаться в зависимости от того в каком предложении (контексте) он стоит. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Как мы можем использовать Берт?  \n",
    "\n",
    "\n",
    "\n",
    "- Можем его использовать чтобы получить эмбединги и подать их в наши модели как альтернативу векторов от TFIDF/CountVectorizer (чтобы это реализовать можно взять готовый код в тренажёре) - Таким образом мы получаем, (если выбрать верную модель)  метрику за 0,9. \n",
    "    \n",
    "    \n",
    "    \n",
    "- Можно потюнить модель Берта,  можешь взять на основу [статью (там вообще все возможные варианты рассмотрены, причём с использованием разных библиотек)](https://habr.com/ru/articles/704592/) или этот [ролик](https://www.youtube.com/watch?v=Z1J3sTJYIcc&list=PLEwK9wdS5g0qksxWxtE5c2KuFkIfUXe3i&index=14), там прямо можно посмотреть процесс кодирования, и получше разобраться в практической релизации Берта (тут реализация сложнее, метрики я видел за 0,8). Если использовать [Trainer](https://pytorch.org/rl/reference/generated/torchrl.trainers.Trainer.html), будет всё гораздо проще. \n",
    "    \n",
    "    \n",
    "    \n",
    "- И третий вариант еще проще, использовав уже готовые [модели](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html), даже без тюнинга, которые предсказывают токсичный текст на английском или нет. Использовав эту [схему](https://huggingface.co/unitary/toxic-bert), я видел полученную метрику за 0,9, даже без тюнинга \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "Андрей, в конце проекта принято кратко описывать все проделанные шаги и полученные результаты. Зачем это нужно - когда проект захочет посмотреть будущий работодатель, у него может не быть времени на подробный разбор кода. Вероятнее всего он бегло просмотрит код, но захочет изучить результат, который будет в общем выводе. Поэтому все же советую написать общий вывод пообьемней: добавить пару слов о данных, работе с ними, о моделях, метриках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Андрей, у тебя старательно выполненная работа, все четко, осмысленно. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Логика моделирования не нарушена, GS использован корректно. И здорово что использовал его вместе с pipeline. Можешь попробовать feature_engenering, часто именно это и позволяет улучшить качество прогнозирования (как это можно сделать я написал). Даже если результата не будет, прокачаешь новые скилы\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Можешь попробовать очень современный и модный сейчас подход с использованием  Берта. Есть несколько вариантов, самый эффективный - это использовать эмбединги (как замена TFIDF) для этого есть уже готовый код в тренажёре (в этом случае разрешается сильно порезать датасет, а если еще и использовать GPU в Colab код можно прогнать за полчаса).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- WordNetLemmatizer используем с POS - тег \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- при инициализации модели не забываем random_state (можно один раз вначале просто прописать random.seed(42), чтобы не прописывать каждый раз везде random_state. Кстати знаешь откуда 42?)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "\n",
    "Если нравится смотреть и слушать то есть целый курс на Ютубе https://www.youtube.com/watch?v=qDMwIQRQt-M&list=PLEwK9wdS5g0qksxWxtE5c2KuFkIfUXe3i&index=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Спасибо за работу!    \n",
    "\n",
    "    \n",
    "\n",
    "Красного нет, вопросов нет, значит все, пора принимать) Надеюсь мои советы и вопросики были полезны и в копилочку знаний упало что то новое, а проект стал лучше, и симпатичней.\n",
    "\n",
    "  \n",
    "Отличная работа Андрей. Желаю успехов в дальнейшей учебе!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2446,
    "start_time": "2023-06-21T12:42:20.904Z"
   },
   {
    "duration": 3491,
    "start_time": "2023-06-28T07:54:58.082Z"
   },
   {
    "duration": 4915,
    "start_time": "2023-06-28T07:55:44.198Z"
   },
   {
    "duration": 174,
    "start_time": "2023-06-28T07:55:52.405Z"
   },
   {
    "duration": 129,
    "start_time": "2023-06-28T07:56:04.010Z"
   },
   {
    "duration": 3413,
    "start_time": "2023-06-28T07:56:12.206Z"
   },
   {
    "duration": 4392,
    "start_time": "2023-06-28T07:56:18.509Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-28T07:56:29.045Z"
   },
   {
    "duration": 143,
    "start_time": "2023-06-28T07:56:45.369Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-28T07:56:48.737Z"
   },
   {
    "duration": 5638,
    "start_time": "2023-06-28T07:57:06.993Z"
   },
   {
    "duration": 215,
    "start_time": "2023-06-28T08:04:57.713Z"
   },
   {
    "duration": 37693,
    "start_time": "2023-06-28T08:05:14.847Z"
   },
   {
    "duration": 38188,
    "start_time": "2023-06-28T08:07:26.702Z"
   },
   {
    "duration": 34719,
    "start_time": "2023-06-28T08:09:02.754Z"
   },
   {
    "duration": 1047,
    "start_time": "2023-06-28T08:11:42.874Z"
   },
   {
    "duration": 789,
    "start_time": "2023-06-28T08:12:05.410Z"
   },
   {
    "duration": 40477,
    "start_time": "2023-06-28T10:24:31.646Z"
   },
   {
    "duration": 3113,
    "start_time": "2023-06-28T10:25:52.604Z"
   },
   {
    "duration": 3194,
    "start_time": "2023-06-28T10:25:55.721Z"
   },
   {
    "duration": 407,
    "start_time": "2023-06-28T10:25:58.917Z"
   },
   {
    "duration": 1500,
    "start_time": "2023-06-28T10:25:59.326Z"
   },
   {
    "duration": 186,
    "start_time": "2023-06-28T10:26:00.828Z"
   },
   {
    "duration": 796,
    "start_time": "2023-06-28T10:26:01.016Z"
   },
   {
    "duration": 40357,
    "start_time": "2023-06-28T10:26:01.814Z"
   },
   {
    "duration": 41409,
    "start_time": "2023-06-28T10:26:46.542Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-28T10:32:32.635Z"
   },
   {
    "duration": 866,
    "start_time": "2023-06-28T10:33:37.975Z"
   },
   {
    "duration": 42006,
    "start_time": "2023-06-28T10:34:30.624Z"
   },
   {
    "duration": 42597,
    "start_time": "2023-06-28T10:35:38.672Z"
   },
   {
    "duration": 42299,
    "start_time": "2023-06-28T10:38:56.298Z"
   },
   {
    "duration": 40412,
    "start_time": "2023-06-28T10:40:45.907Z"
   },
   {
    "duration": 3217,
    "start_time": "2023-06-28T10:42:36.322Z"
   },
   {
    "duration": 5430,
    "start_time": "2023-06-28T10:42:39.542Z"
   },
   {
    "duration": 171,
    "start_time": "2023-06-28T10:42:44.977Z"
   },
   {
    "duration": 729,
    "start_time": "2023-06-28T10:42:45.151Z"
   },
   {
    "duration": 735,
    "start_time": "2023-06-28T10:42:45.883Z"
   },
   {
    "duration": 39511,
    "start_time": "2023-06-28T10:42:46.620Z"
   },
   {
    "duration": 38218,
    "start_time": "2023-06-28T10:48:52.984Z"
   },
   {
    "duration": 823,
    "start_time": "2023-06-28T10:50:38.585Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-28T10:50:58.975Z"
   },
   {
    "duration": 40381,
    "start_time": "2023-06-28T10:51:21.791Z"
   },
   {
    "duration": 39990,
    "start_time": "2023-06-28T10:56:02.895Z"
   },
   {
    "duration": 39490,
    "start_time": "2023-06-28T10:57:04.375Z"
   },
   {
    "duration": 669,
    "start_time": "2023-06-28T10:58:09.706Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-28T10:58:25.109Z"
   },
   {
    "duration": 166259,
    "start_time": "2023-06-28T10:58:32.612Z"
   },
   {
    "duration": 6736,
    "start_time": "2023-06-28T11:10:12.971Z"
   },
   {
    "duration": 4380,
    "start_time": "2023-06-28T11:10:27.893Z"
   },
   {
    "duration": 17678,
    "start_time": "2023-06-28T11:10:39.307Z"
   },
   {
    "duration": 118424,
    "start_time": "2023-06-28T11:10:56.987Z"
   },
   {
    "duration": 24860,
    "start_time": "2023-06-28T11:12:55.413Z"
   },
   {
    "duration": 195,
    "start_time": "2023-06-28T11:13:29.743Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-28T11:13:30.001Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-28T11:13:30.239Z"
   },
   {
    "duration": 8707,
    "start_time": "2023-06-28T11:13:41.780Z"
   },
   {
    "duration": 3113,
    "start_time": "2023-06-28T20:57:33.422Z"
   },
   {
    "duration": 3099,
    "start_time": "2023-06-28T20:57:36.538Z"
   },
   {
    "duration": 4602,
    "start_time": "2023-06-28T20:57:39.639Z"
   },
   {
    "duration": 2688,
    "start_time": "2023-06-28T20:57:44.243Z"
   },
   {
    "duration": 188,
    "start_time": "2023-06-28T20:57:46.933Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-28T20:57:47.123Z"
   },
   {
    "duration": 707,
    "start_time": "2023-06-28T20:57:47.128Z"
   },
   {
    "duration": 6229,
    "start_time": "2023-06-28T20:57:47.837Z"
   },
   {
    "duration": 4968,
    "start_time": "2023-06-28T20:57:54.068Z"
   },
   {
    "duration": 13215,
    "start_time": "2023-06-28T20:57:59.039Z"
   },
   {
    "duration": 88870,
    "start_time": "2023-06-28T20:58:12.255Z"
   },
   {
    "duration": 21120,
    "start_time": "2023-06-28T20:59:41.126Z"
   },
   {
    "duration": 38,
    "start_time": "2023-06-28T21:02:38.338Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-28T21:05:26.799Z"
   },
   {
    "duration": 161,
    "start_time": "2023-06-28T21:05:27.772Z"
   },
   {
    "duration": 96,
    "start_time": "2023-06-28T21:05:54.244Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-28T21:06:34.277Z"
   },
   {
    "duration": 1016,
    "start_time": "2023-06-28T21:06:37.701Z"
   },
   {
    "duration": 254,
    "start_time": "2023-06-28T21:08:37.755Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-28T21:08:42.432Z"
   },
   {
    "duration": 4251288,
    "start_time": "2023-06-28T21:08:43.460Z"
   },
   {
    "duration": 549,
    "start_time": "2023-06-29T02:36:20.146Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-29T07:12:01.848Z"
   },
   {
    "duration": 364,
    "start_time": "2023-06-29T07:18:55.333Z"
   },
   {
    "duration": 4525,
    "start_time": "2023-06-29T09:38:00.450Z"
   },
   {
    "duration": 3705,
    "start_time": "2023-06-29T09:38:15.241Z"
   },
   {
    "duration": 3190,
    "start_time": "2023-06-29T09:38:18.949Z"
   },
   {
    "duration": 453,
    "start_time": "2023-06-29T09:38:22.141Z"
   },
   {
    "duration": 3747,
    "start_time": "2023-06-29T09:38:27.998Z"
   },
   {
    "duration": 150,
    "start_time": "2023-06-29T09:38:31.747Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-29T09:38:31.899Z"
   },
   {
    "duration": 592,
    "start_time": "2023-06-29T09:38:31.905Z"
   },
   {
    "duration": 6772,
    "start_time": "2023-06-29T09:38:35.940Z"
   },
   {
    "duration": 4337,
    "start_time": "2023-06-29T09:38:42.714Z"
   },
   {
    "duration": 14759,
    "start_time": "2023-06-29T09:38:47.053Z"
   },
   {
    "duration": 83566,
    "start_time": "2023-06-29T09:39:01.814Z"
   },
   {
    "duration": 544645,
    "start_time": "2023-06-29T09:41:00.257Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-29T09:50:04.904Z"
   },
   {
    "duration": 26793,
    "start_time": "2023-06-29T10:55:48.352Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-29T10:56:25.660Z"
   },
   {
    "duration": 39,
    "start_time": "2023-06-29T10:56:54.085Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-29T10:58:33.736Z"
   },
   {
    "duration": 1354,
    "start_time": "2023-06-29T11:03:40.655Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-29T18:33:48.670Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-29T18:35:42.443Z"
   },
   {
    "duration": 7682,
    "start_time": "2023-06-29T18:35:48.232Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-29T18:36:01.958Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-29T18:36:58.710Z"
   },
   {
    "duration": 5785,
    "start_time": "2023-06-29T18:37:22.797Z"
   },
   {
    "duration": 5699,
    "start_time": "2023-06-29T18:37:55.821Z"
   },
   {
    "duration": 4714,
    "start_time": "2023-06-29T18:39:33.440Z"
   },
   {
    "duration": 15979,
    "start_time": "2023-06-29T18:40:11.885Z"
   },
   {
    "duration": 15794,
    "start_time": "2023-06-29T18:41:07.760Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-29T18:42:22.496Z"
   },
   {
    "duration": 6097,
    "start_time": "2023-06-29T18:57:38.968Z"
   },
   {
    "duration": 5368,
    "start_time": "2023-06-29T18:58:11.600Z"
   },
   {
    "duration": 14673,
    "start_time": "2023-06-29T18:58:30.265Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-29T18:59:12.067Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-29T18:59:27.963Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-29T19:01:08.577Z"
   },
   {
    "duration": 2086,
    "start_time": "2023-06-29T19:01:24.832Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-29T19:01:32.301Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-29T19:01:58.730Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-29T19:02:05.459Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-29T19:02:11.403Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-29T19:05:07.725Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-29T19:06:32.791Z"
   },
   {
    "duration": 1898,
    "start_time": "2023-06-29T19:07:00.798Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-29T19:08:51.111Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-29T19:09:18.303Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-29T19:09:45.822Z"
   },
   {
    "duration": 6049,
    "start_time": "2023-06-29T19:12:02.936Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-29T19:12:43.188Z"
   },
   {
    "duration": 2257,
    "start_time": "2023-06-29T19:13:03.894Z"
   },
   {
    "duration": 2136,
    "start_time": "2023-06-29T19:13:06.153Z"
   },
   {
    "duration": 4842,
    "start_time": "2023-06-29T19:13:08.291Z"
   },
   {
    "duration": 3437,
    "start_time": "2023-06-29T19:13:13.135Z"
   },
   {
    "duration": 136,
    "start_time": "2023-06-29T19:13:16.574Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-29T19:13:16.712Z"
   },
   {
    "duration": 513,
    "start_time": "2023-06-29T19:13:16.716Z"
   },
   {
    "duration": 317,
    "start_time": "2023-06-29T19:13:17.231Z"
   },
   {
    "duration": 2917,
    "start_time": "2023-06-29T19:14:02.520Z"
   },
   {
    "duration": 2403,
    "start_time": "2023-06-29T19:14:05.439Z"
   },
   {
    "duration": 454,
    "start_time": "2023-06-29T19:14:07.843Z"
   },
   {
    "duration": 1078,
    "start_time": "2023-06-29T19:14:08.299Z"
   },
   {
    "duration": 373,
    "start_time": "2023-06-29T19:14:09.379Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-29T19:14:09.754Z"
   },
   {
    "duration": 496,
    "start_time": "2023-06-29T19:14:09.768Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-29T19:14:10.266Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-29T19:14:26.361Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-29T19:14:40.122Z"
   },
   {
    "duration": 1020010,
    "start_time": "2023-06-29T19:14:47.009Z"
   },
   {
    "duration": 2141409,
    "start_time": "2023-06-29T19:32:37.350Z"
   },
   {
    "duration": 11029,
    "start_time": "2023-06-29T20:09:48.946Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-29T20:10:10.860Z"
   },
   {
    "duration": 2366,
    "start_time": "2023-06-29T20:10:57.991Z"
   },
   {
    "duration": 1412,
    "start_time": "2023-06-29T20:11:22.026Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-29T20:11:27.650Z"
   },
   {
    "duration": 198067,
    "start_time": "2023-06-29T20:11:42.113Z"
   },
   {
    "duration": 192792,
    "start_time": "2023-06-29T20:15:40.705Z"
   },
   {
    "duration": 1338,
    "start_time": "2023-06-29T20:21:24.695Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-29T20:22:48.327Z"
   },
   {
    "duration": 202056,
    "start_time": "2023-06-29T20:22:50.814Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-29T20:27:27.412Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-29T20:27:33.810Z"
   },
   {
    "duration": 55,
    "start_time": "2023-06-29T20:28:07.208Z"
   },
   {
    "duration": 1629,
    "start_time": "2023-06-29T20:28:23.807Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-29T20:28:28.743Z"
   },
   {
    "duration": 4068828,
    "start_time": "2023-06-29T20:28:31.163Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-29T21:36:19.994Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
